{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(3 pts) What is a neural network? What are the general steps required to build a neural network?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A neural network is a computational model inspired by the human brain, consisting of layers of interconnected nodes (neurons) that process data and learn patterns to solve tasks like classification, regression, and prediction. The general steps required to build a neural network are to:\n",
    "1. Prepare the Data: Gather, clean, and preprocess the dataset.\n",
    "\n",
    "2. Model Selection: Select the model you want to use.\n",
    "\n",
    "3. Define the Model: Further define the model(layers, neurons per layer, activation functions, etc.)\n",
    "\n",
    "4. Initialize the Parameters: Set the weights and biases.\n",
    "\n",
    "5. Forward Propagation: Pass the input data through the network and compute the predictions.\n",
    "\n",
    "6. Compute Loss: Measure the error of the function that you are using.\n",
    "\n",
    "7. Backward Propagation: Calculate gradients of the loss with respect to the weights and biases that were set prior.\n",
    "\n",
    "8. Update Parameters: Adjust the weights and biases using an optimization algorithm.\n",
    "\n",
    "9. Evaluate Performance: Test the model.\n",
    "\n",
    "10. Deploy Model: Use the trained model for predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(3 pts) Generally, how do you check the performance of a neural network? Why is this the case?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You check a neural network's performance using metrics like accuracy, precision, recall, or loss on a validation/test set. This ensures the model generalizes well to unseen data, avoiding overfitting and underfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(4 pts) Clean the data or do additional cleaning if you have used the dataset for another assignment. Specify the improvements (at least 2) that you made to your cleaning if you selected the dataset before. If you select one with a low number or records, consider oversampling.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "card = pd.read_csv(\"Credit_card.csv\")\n",
    "\n",
    "label = pd.read_csv(\"Credit_card_label.csv\")\n",
    "\n",
    "data = card.merge(label, on = \"Ind_ID\", how = \"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_encoder(data, columns):\n",
    "    labelencoder = preprocessing.LabelEncoder()\n",
    "    for column in columns:\n",
    "        if column in data.columns:\n",
    "            data[column] = labelencoder.fit_transform(data[column].astype(str))\n",
    "    data.fillna(data.mean(numeric_only=True), inplace=True)\n",
    "    numeric_columns = data.select_dtypes(include=[\"float64\", \"int64\"]).columns    \n",
    "    scaler = StandardScaler()\n",
    "    data[numeric_columns] = scaler.fit_transform(data[numeric_columns])\n",
    "    for col in numeric_columns:\n",
    "        if col in data.columns:\n",
    "            Q1 = data[col].quantile(0.25)\n",
    "            Q3 = data[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "            data[col] = data[col].clip(lower=lower_bound, upper=upper_bound)\n",
    "    return data\n",
    "\n",
    "encode_column = [\"Car_Owner\", \"GENDER\", \"Propert_Owner\", \"Marital_status\", \n",
    "                 \"EDUCATION\", \"Housing_type\", \"Type_Occupation\", \"Type_Income\"]\n",
    "\n",
    "data = column_encoder(data, encode_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Improvements:\n",
    "1. StandardScaler was used to scale all numerical columns to have a mean equal to zero and a standard deviation of 1.\n",
    "\n",
    "2. IQR Outlier Capping was used so that the numerical data are capped at 1.5 times the interquartile range which has many benefits such as improving model performance, prevents overfitting, minimizes distortions, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(10 pts) Create a neural network using Keras or PyTorch to predict the outcome of your datasets.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "X = data.drop('label', axis =1).values\n",
    "y = data['label'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=42)\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "y_test = torch.LongTensor(y_test)\n",
    "y_train = torch.LongTensor(y_train)\n",
    "\n",
    "class ANN_Model(nn.Module):\n",
    "    def __init__(self,input_features=18,hidden1=20,hidden2=20,out_features=2):\n",
    "        super().__init__()\n",
    "        self.layer_1_connection = nn.Linear(input_features, hidden1)\n",
    "        self.layer_2_connection = nn.Linear(hidden1,hidden2)\n",
    "        self.out = nn.Linear(hidden2, out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer_1_connection(x))\n",
    "        x = F.relu(self.layer_2_connection(x))\n",
    "        s = self.out(x)\n",
    "        return x\n",
    "\n",
    "torch.manual_seed(42)\n",
    "ann = ANN_Model()\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(ann.parameters(), lr = 0.01)\n",
    "\n",
    "final_loss = []\n",
    "n_epochs = 500\n",
    "for epochs in range (n_epochs):\n",
    "    y_pred = ann.forward(X_train)\n",
    "    loss = loss_function(y_pred, y_train)\n",
    "    final_loss.append(loss)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(X_test):\n",
    "        prediction = ann(data)\n",
    "        y_pred.append(prediction.argmax())\n",
    "\n",
    "y_pred = torch.tensor(y_pred).numpy()\n",
    "y_test = y_test.numpy()\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(5 pts) Compare the performance of the neural networks to another model you created. Which performed better? Why do you think that is?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance of the neural network compared to the logistic regression model that I used in a prior assignment is night an day. The logistic regression had an accuracy score of 84.52% while the neural network had an accuracy of 100.00%. The neural network outperformed logistic regression because it can model complex, non-linear relationships in the data, while logistic regression is limited to linear boundaries. If the dataset has non-linear patterns, many features, or perfect separability, the neural network's flexibility gives it a clear advantage. However, the 100% accuracy suggests the possibility of overfitting, especially if the dataset is small or lacks noise. Proper validation (e.g., cross-validation) is necessary to confirm the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extra credit: (3 pts) for using Keras and PyTorch. Additional (2 pts) for identifying an optimal activation function and optimizer function for the dataset you chose.**\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
